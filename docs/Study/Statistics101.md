---
layout: default
title:  "[책] 통계 101 x 데이터 분석"
parent: Study
permalink: /study/Statistics101/
nav_order: 3
date: 2023-07-28
---

***
<dl>
  <dt>책 제목</dt>
  <dd>통계 101 x 데이터 분석</dd>
<dt>출판연월</dt>
  <dd>22년 10월</dd>
  <dt>지은이</dt>
  <dd>아베 마사토</dd>
</dl>
***

실무에서 통계 지식은 아예 안 쓰이진 않는데, 높은 수준을 요하는 것이 아닌, 기본적인 지식을 누구나 쉽게 이해할 수 있게끔 설명하는 능력이 더 중요한 것 같다. 그래서 기본 개념에 대한 이해를 다잡고, 쉽게 설명하기 위한 역량을 기르고자 책을 구했다.

제 1종 오류와 제 2종 오류 (139p)

- 대립가설: 밝히고 싶은 가설
- 귀무가설: 밝히고자 하는 가설의 부정 명제
- 1종 오류(false positive): 귀무가설이 옳음에도 귀무가설을 기각하고 대립가설을 채택. 1종 오류가 일어날 확률을 alpha로 나타냄
  - 약의 효과가 없는데도(귀무 옳음), 효과가 있다고 판단(대립 채택)
  - 귀무가설이 옳다는 것은 알 수 없음. 모집단을 직접 알 수 없기 때문. 그래서 1종 오류가 얼마나 될지 알 수는 없음
  - 다만 상한을 정하는 방식 등으로 이 오류 확률을 통제할 수 있음
  - 귀무가설을 언제 기각할 것인지? alpha' 보다 p 값이 작을 때라고 한다면, 이게 결국 alpha임
  - 유의수준 alpha' 값을 미리 0.05와 같은 값으로 정해서 alpha를 통제하는 셈
- 2종 오류(false negative): 대립가설이 옳음에도 귀무가설을 기각하지 않는 것. 2종 오류가 일어날 확률을 beta로 나타냄
  - 실제론 약의 효과가 있는데(대립 옳음), 효과 있다고 보지 않는 판단(대립 기각 x)하는 것
  - beta는 n이 커질수록 작아짐
  - 그래서 1-beta가 80%가 되도록 표본 크기를 설계하는 것이 이상적임
  - 또한 beta는 효과 크기(MDE..?)가 커질수록 작아짐
  - 효과 크기가 클수록 분포가 겹치는 부분이 줄어들어 검출이 간단해지기 때문이라는데, 큰 효과를 검증하는 것은 그만큼 적은 표본으로도 충분히 검증하다는 직관적인 이해가 가능함
  - MDE가 작은 지표일수록 많은 표본이 필요하다는 A/B test 스터디 내용과 상통함

회귀

- 책에선, 회귀를 'y=f(x)라는 함수를 통해 변수 사이 관계를 공식화하는 것'이라고 정의한 것이 인상 깊음

오즈

- 오즈(odds)란, 어떤 사건이 일어날 확률 p와 일어나지 않을 확률 1-p의 비율
- 확률 p를 [0, inf]의 범위로 변환한 값으로 볼 수 있음
- 원래 도박에서 쓰인 지표로, 예를 들어 p = 0.2이면 odds = 0.2 / 0.8 = 1/4 이므로, 이기면 판돈의 4배를 받을 수 있다는 지표로 사용되었음
- 이런 예시.. 이해가 그나마 쉬운 듯. 상식적인 개념이니까 알고 있을 것

재현성 위기

- 과학의 중요한 특징 중 하나인 재현성(reproducibility, replication)
- 누가 언제, 어디서 실험해도, 조건이 동일하다면 동일한 결과를 얻을 수 있어야 한다는 것
- 

p-value

- p 값은 표본 크기에도 의존하며, n이 클 때는 작은 차이라 해도 p < 0.05가 될 수 있음
- 작은 효과를 검정하기 위해선 큰 n이 필요한 것과 같은 논리
- 따라서 검출하고자 하는 효과 크기를 사전에 설정하고, 표본 크기 n을 설정해야 함
- 그런데 이렇게 정석적으로 진행된 실험이 얼마나 될까...
- 필자는 p < 0.05에만 관심 두어서는 안되면, 효과 크기나 신뢰 구간을 같이 봐야 한다고 함
- 큰 표본은 반가운 것


베이즈 인수

- 위와 같은 p 값의 한계를 보완할 수 있는 지표
- 자세한건... 패스

p-hacking

- p가 0.05보다 작아질 때 까지 표본크기를 늘림
- 처음에는 n = 30으로 실험해서 p가 0.07인데, 이후 n = 40으로 실험했더니, p가 0.05보다 작아져서 이를 보고함
- 여러 요인을 탐색해서 그 중 p가 0.05보다 작은 것만 보고함
- 중간에 HARking 이란 개념이 나오는데, Hypothesis After the Results are Known의 약자로, 데이터를 얻어 결과 보고 나서 가설을 만드는 행위라고 함.
- 가설 설정이 중요함은 끊임없이 강조되고 있는데, 정작 안 지켜지는 경우가 꽤 많다. 그런 때를 대비해서라도 위 용어를 염두에 둘 것

인과와 상관

- 흔히 상관 != 인과라고 함. 인과를 파악하면 결국 input var를 가지고 output var를 통제하는 '개입'이 가능하기 때문
- 그럼 상관은 왜 중요하냐?
  - 상관이 있다면 인과가 존재할 가능성이 있음을 의미
  - 인과를 명확히 파악하기 전 단계로서 상관을 이용해서 인과와 관련된 변수 후보를 압축할 수 있음
  - 상관관계를 통해 한쪽 변수로부터 다른 변수를 '예측'할 수 있음
    - X를 바꾸면 Y가 어떻게 변화하는지가 아님
    - 동일 조건에서 새로운 X를 관찰했을 때, 그로부터 Y 값을 예측하는 것

인과관계를 밝히려면?

- 인과를 밝히기 어려운 이유는 중첩 요인이 얼마나 있고, 각 중첩 요인의 영향력이 얼마나 되는지 파악하기 어렵기 때문
- 그러므로 요인을 통제하는 실험을 통해 인과 관계를 밝힐 수 있음 (Randomized Control Trial, Propensity Score Matching 등)
  - RCT는 중첩 요인을 무효화시켜 인과를 밝힘
- RCT에는 흔히 우리가 접하는 A/B test가 있음
- RCT는 직접적인 개입을 하는 실험인데, 이런 개입이 불가능한 경우, 데이터에서 인과 효과를 추정해볼 수 있음
  - 다중 회귀: 중첩 요인을 회귀 모델에 변수로 넣어서 계수를 추정하는 것
  - 층별 해석: 중첩 요인을 기준으로 segment를 나눠 분석. 즉, 중첩 요인의 효과를 가능한 작게 쪼개는 셈
  - PSM: 중첩요인 값이 비슷한 데이터를 짝지어 분석 = 중첩 요인 효과를 없애고, RCT와 비슷한 효과를 얻을 수 있음
  - 이중차분법: Difference In Difference라고 하는데.. 잘 모르겠음

수리 모형

- 일단 모형이란? 현상에서 본질을 뽑아 간략화한 것. 복잡한 현상을 잘 이해하는 도구
- 세가지 종류가 있음
  - 통계 모형: 이해, 예측, 제어가 목적. 귀납적 접근 방식
    - 데이터를 이용해 모형화
    - 상대적으로 적은 양의 데이터를 요함
    - 단순한 구조로 해석이 쉬움
  - 기계학습 모형: 예측 목적. 귀납적 접근 방식
    - 데이터를 이용해 모형화
    - 대량의 데이터 필요
    - 복잡한 구조로 해석이 어려움
  - 수리 모형: 이해, 예측, 제어가 목적. 연역적 접근 방식
    - 현상의 메커니즘을 가정해 모형화하는 것
    - 파라미터를 바꾸면 발생하는 현상에 관심 있음
    - 가상의 세계를 상정하고 어떤 규칙을 적용했을 때 무엇이 일어나는지 조사하는 방법
- 수리 모형은 크게 두가지로 나눌 수 있음
  - 결정론 모형: 미분 방정식, 차분 방정식, 편미분 방정식
    - 왜 결정론이라 할까? 특정 시각의 상태가 정해지면, 다른 시각의 상태는 하나로 결정되는 성질에 대한 것이라서 (생각해보면 확률과 반대되는 개념이긴 함. 공을 던지면 어디에 떨어질지 예측할 수 있는 것 등)
  - 확률 모형: 무작위 행보, 마르코프 연쇄 (이게 바로 지금 이 글을 쓰는 이유... 학부 때 배운 확률 모형을 이렇게 뿌리부터 접근하니 등 긁히는 느낌)
    - 확률적인 움직임이 본질인 현상. 예를 들어 도박의 결과.
    - Random Walk
    - Markov Process: 무작위 행보를 일반화한 확률 과정. 과거 상태와 관계없이 현재 상태에 따라 다음 상태가 결정되는 확률 과정 (이런 성질을 마크로프 성질이라고 함)
- 확률 과정: 확률적으로 시간 변동하는 현상을 기술하는 일종의 수리 모형
